import groovy.json.JsonSlurper
def currentRelease
def previousRelease
pipeline
{
	agent any
	stages
	{
		// This stage checks that an upstream step, UniProt Update, was run successfully.
		stage('Check UniProt Update build succeeded')
		{
			steps
			{
				script
				{
					// Get current release number from directory
					currentRelease = (pwd() =~ /Releases\/(\d+)\//)[0][1];
					previousRelease = (pwd() =~ /Releases\/(\d+)\//)[0][1].toInteger() - 1;
					// This queries the Jenkins API to confirm that the most recent build of 'UniProt Update' was successful.
					def uniprotStatusUrl = httpRequest authentication: 'jenkinsKey', validResponseCodes: "${env.VALID_RESPONSE_CODES}", url: "${env.JENKINS_JOB_URL}/job/${currentRelease}/job/Pre-Slice/job/UniProtUpdate/lastBuild/api/json"
					if (uniprotStatusUrl.getStatus() == 404)
					{
						error("UniProt Update has not yet been run. Please complete a successful build.")
					}
					else
					{
						def uniprotStatusJson = new JsonSlurper().parseText(uniprotStatusUrl.getContent())
						if (uniprotStatusJson['result'] != "SUCCESS")
						{
							error("Most recent UniProt Update build status: " + uniprotStatusJson['result'] + ". Please complete a successful build.")
						}
					}
				}
			}
		}
		// This stage backs up the gk_central database before it is modified.
		stage('Setup: Back up gk_central - pre-update')
		{
			steps
			{
				script
				{
					withCredentials([usernamePassword(credentialsId: 'mySQLCuratorUsernamePassword', passwordVariable: 'pass', usernameVariable: 'user')])
					{
						def central_before_cosmic_update_dump = "${env.GK_CENTRAL}_${currentRelease}_before_cosmic_update.dump"
						sh "mysqldump -u$user -p$pass -h${env.CURATOR_SERVER} ${env.GK_CENTRAL} > $central_before_cosmic_update_dump"
						sh "gzip -f $central_before_cosmic_update_dump"
					}
				}
			}
		}
		// Builds the jar file using Maven.
		stage('Setup: Build jar file')
		{
			steps
			{
				script
				{
					sh "mvn -DskipTests clean compile assembly:single"
				}
			}
		}
		// Download the data files. Done as a separate step from the main program's execution so that if
		// the program fails, you don't get stuck waiting for a long download again. 
		stage('Download COSMIC files')
		{
			steps
			{
				script
				{
					withCredentials([file(credentialsId: 'Config', variable: 'ConfigFile')])
					{
						sh "java -Xmx${env.JAVA_MEM_MAX}m -jar target/cosmic-update-*-jar-with-dependencies.jar -d PT72H"
					}
				}
			}
		}
		// Run the COSMIC Update
		stage('Run COSMIC updates')
		{
			steps
			{
				script
				{
					withCredentials([usernamePassword(credentialsId: 'mySQLCuratorUsernamePassword', passwordVariable: 'pass', usernameVariable: 'user')])
					{
						sh "java -Xmx${env.JAVA_MEM_MAX}m -jar target/cosmic-update-*-jar-with-dependencies.jar -u"
					}
				}
			}
		}
		// This stage backs up the gk_central database after modification.
		stage('POST: Backup gk_central - post-update')
		{
			steps
			{
				script
				{
					withCredentials([usernamePassword(credentialsId: 'mySQLCuratorUsernamePassword', passwordVariable: 'pass', usernameVariable: 'user')])
					{
						def central_after_update_cosmic_update_dump = "${env.GK_CENTRAL}_${currentRelease}_after_cosmic_update.dump"
						sh "mysqldump -u$user -p$pass -h${env.CURATOR_SERVER} ${env.GK_CENTRAL} > $central_after_update_cosmic_update_dump"
						sh "gzip -f $central_after_update_cosmic_update_dump"
					}
				}
			}
		}
		// This stage archives the contents of the 'reports' folder generated by COSMIC Update and sends them in an email to the default recipients list.
		stage('Post: Email COSMIC Update Reports')
		{
			steps
			{
				script
				{
					sh "tar zcf cosmic-update-v${currentRelease}-reports.tgz reports/"
					emailext (
						body: "Hello,\n\nThis is an automated message from Jenkins regarding an update for v${currentRelease}. The COSMIC Update step has completed. Please review the reports attached to this email. If they look correct, these reports need to be uploaded to the Reactome Drive at Reactome>Release>Release QA>V${currentRelease}_QA>V${currentRelease}_COSMIC_Update_Reports. The URL to the new V${currentRelease}_COSMIC_Update_Reports folder also needs to be updated at https://devwiki.reactome.org/index.php/Reports_Archive under 'COSMIC Update Reports'. Please add the current COSMIC report wiki URL to the 'Archived reports' section of the page. If the reports don't look correct, please email the developer running Release. \n\nThanks!",
						to: '$DEFAULT_RECIPIENTS',
						from: "${env.JENKINS_RELEASE_EMAIL}",
						subject: "COSMIC Update Reports for v${currentRelease}",
						attachmentsPattern: "**/cosmic-update-v${currentRelease}-reports.tgz"
					)
				}
			}
		}
		// All databases, logs, and data files generated by this step are compressed before moving them to the Reactome S3 bucket. 
		// All files are then deleted.
		stage('Post: Archive Outputs')
		{
			steps
			{
				script
				{
					def s3Path = "${env.S3_RELEASE_DIRECTORY_URL}/${currentRelease}/cosmic_update"
					sh "mkdir -p databases/ data/"
					sh "mv --backup=numbered *_${currentRelease}_*.dump.gz databases/"
					sh "gzip data/* logs/*"
					sh "mv cosmic-update-v${currentRelease}-reports.tgz data/"
					sh "aws s3 --no-progress --recursive cp databases/ $s3Path/databases/"
					sh "aws s3 --no-progress --recursive cp logs/ $s3Path/logs/"
					sh "aws s3 --no-progress --recursive cp data/ $s3Path/data/"
					sh "rm -r databases logs data reports"
				}
			}
		}
	}
}